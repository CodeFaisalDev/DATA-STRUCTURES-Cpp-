# Complexity Analysis

In programming programmers offten have two qustions. That is:
How much time dose a algorithm take?
How make space a algorithm need?

# Big-O Notation

“Big O notation is a mathematical notation that describes the limiting behavior of a function when the argument tends towards a particular value or infinity. It is a member of a family of notations invented by Paul Bachmann, Edmund Landau, and others, collectively called Bachmann–Landau notation or asymptotic notation.”

— Wikipedia’s definition of Big O notation

In plain words, Big O notation describes the complexity of your code using algebraic terms.

To understand what Big O notation is, we can take a look at a typical example, O(n²), which is usually pronounced “Big O squared”. The letter “n” here represents the input size, and the function “g(n) = n²” inside the “O()” gives us an idea of how complex the algorithm is with respect to the input size.


### Complexitys in form smallest to largest(n is the size of input)
* CONSTANT TIME = O(1)
* LOGERITHMIC TIME = O(log(n))
* LINEAR TIME = O(n)
* LINEARITHMIC TIME = O(nlog(n))
* QUADRIC TIME = $`O(n^2)`$
* CUBIC TIME = $`O(n^3)`$
* EXPONENTIOA TIME = $`O(b^n)`$
* FACTORIAL TIME = O(n!)
